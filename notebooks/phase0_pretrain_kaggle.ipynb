{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 0 Pre-training - Unified Multi-Modal WaveFormer\n",
    "## RSNA 2025 Project\n",
    "\n",
    "**Main Entry Point**: Based on `source/train_phase0_subset.py`\n",
    "\n",
    "### What this notebook does:\n",
    "1. Train **unified** WaveFormer handling both MRI (1-channel) and CT (3-channel)\n",
    "2. Adaptive MiM hierarchical masking with spatial contrastive loss\n",
    "3. Alternating batch training strategy for multi-modal learning\n",
    "4. **Pure SparK sparse operations with MinkowskiEngine** (NO fallback)\n",
    "\n",
    "### Expected runtime:\n",
    "- ~8-10 hours for 50 epochs on Kaggle T4 GPU\n",
    "\n",
    "### Data Requirements:\n",
    "**IMPORTANT**: Upload your preprocessed datasets to Kaggle:\n",
    "1. OpenMind MRI (MRI_T1, MRI_T2, MRA) - 1-channel NIfTI files\n",
    "2. DeepLesion CT - 3-channel NIfTI files (brain/blood/bone windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q ptwt nibabel tqdm\n",
    "\n",
    "# Install MinkowskiEngine from pre-built wheel (fast - ~10 seconds)\n",
    "# Upload wheel to Kaggle dataset first: see WHEEL_BUILD_INSTRUCTIONS.md\n",
    "!pip install /kaggle/input/minkowski-engine-wheel-cuda121-torch240/*.whl\n",
    "\n",
    "# Verify\n",
    "import MinkowskiEngine as ME\n",
    "print(f\"‚úÖ MinkowskiEngine {ME.__version__}, CUDA: {ME.is_cuda_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Source Code from GitHub\n",
    "\n",
    "**Setup**: Push your code to GitHub, then clone here\n",
    "\n",
    "**Required structure**:\n",
    "```\n",
    "source/\n",
    "‚îú‚îÄ‚îÄ modules/phase0/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ models/ (waveformer.py, pretrainer.py, spark_encoder.py)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ data/ (unified_dataloaders.py, transforms.py)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ losses/ (masking.py, contrastive.py)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ utils/ (checkpoint.py)\n",
    "‚îî‚îÄ‚îÄ config/ (phase0_config.py)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nfrom pathlib import Path\n\n# Clone from GitHub\nGITHUB_REPO = \"https://github.com/Thanhjash/RSNA_2025.git\"\n\nif not Path(\"/kaggle/working/RSNA-2025\").exists():\n    print(\"üì• Cloning repository...\")\n    !git clone {GITHUB_REPO} /kaggle/working/RSNA-2025\n    print(\"‚úÖ Repository cloned\")\nelse:\n    print(\"‚úÖ Repository already exists\")\n\n# Add to Python path (correct path after clone)\nsys.path.insert(0, \"/kaggle/working/RSNA-2025\")\n\n# Verify imports\ntry:\n    from source.modules.phase0.models.pretrainer import WaveFormerSparKMiMPretrainer\n    from source.modules.phase0.data.unified_dataloaders import create_unified_dataloaders\n    from source.modules.phase0.utils.checkpoint import CheckpointManager\n    from source.config.phase0_config import get_config\n    print(\"‚úÖ All imports successful\")\nexcept ImportError as e:\n    print(f\"‚ùå Import failed: {e}\")\n    print(f\"Available files: {list(Path('/kaggle/working/RSNA-2025').glob('*'))}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "**Update paths below to match your Kaggle dataset structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get base config\nconfig = get_config('kaggle')\n\n# Optimal T4 GPU configuration (16GB VRAM)\nconfig.img_size = (64, 64, 64)        # Good balance for pre-training\nconfig.batch_size_mri = 6             # Optimized for T4\nconfig.batch_size_ct = 3              # Optimized for T4\nconfig.embed_dim = 768                # Full model\nconfig.depth = 12                     # Full depth\nconfig.num_heads = 12                 # Standard\nconfig.num_workers = 2                # Kaggle CPU limit\nconfig.learning_rate = 1e-4           # Standard\nconfig.weight_decay = 0.05            # Standard\n\n# Data paths - UPDATE THESE!\nconfig.mri_dirs = [\n    \"/kaggle/input/YOUR-MRI-DATASET/MRI_T1\",\n    \"/kaggle/input/YOUR-MRI-DATASET/MRI_T2\",\n    \"/kaggle/input/YOUR-MRI-DATASET/MRA\",\n]\nconfig.ct_dirs = [\n    \"/kaggle/input/YOUR-CT-DATASET/CT\",\n]\n\nprint(\"Configuration:\")\nprint(f\"  Image size: {config.img_size}\")\nprint(f\"  Embed dim: {config.embed_dim}\")\nprint(f\"  Depth: {config.depth}\")\nprint(f\"  Batch sizes: MRI={config.batch_size_mri}, CT={config.batch_size_ct}\")\nprint(f\"  Learning rate: {config.learning_rate}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create DataLoaders\n",
    "\n",
    "Uses **unified multi-modal dataloaders** with alternating batch strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating unified multi-modal dataloaders...\")\n",
    "\n",
    "mri_loader, ct_loader = create_unified_dataloaders(\n",
    "    mri_dirs=config.mri_dirs,\n",
    "    ct_dirs=config.ct_dirs,\n",
    "    img_size=config.img_size,\n",
    "    batch_size_mri=config.batch_size_mri,\n",
    "    batch_size_ct=config.batch_size_ct,\n",
    "    num_workers=config.num_workers,\n",
    "    # For full training: remove max_samples limits\n",
    "    # max_samples_mri=None,\n",
    "    # max_samples_ct=None,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ DataLoaders created:\")\n",
    "print(f\"   MRI: {len(mri_loader.dataset)} samples, {len(mri_loader)} batches\")\n",
    "print(f\"   CT:  {len(ct_loader.dataset)} samples, {len(ct_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Unified Multi-Modal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = WaveFormerSparKMiMPretrainer(\n",
    "    img_size=config.img_size,\n",
    "    in_channels=1,  # Adaptive: handles both 1ch (MRI) and 3ch (CT)\n",
    "    embed_dim=config.embed_dim,\n",
    "    depth=config.depth,\n",
    "    num_heads=config.num_heads,\n",
    "    global_mask_ratio=config.global_mask_ratio,\n",
    "    local_mask_ratio=config.local_mask_ratio,\n",
    "    contrastive_temperature=config.contrastive_temperature,\n",
    "    contrastive_weight=config.contrastive_weight\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel parameters: {total_params:,} ({trainable_params:,} trainable)\")\n",
    "print(f\"                  {total_params/1e6:.2f}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "NUM_EPOCHS = 50  # Update for full training\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCHS,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Checkpoint manager\n",
    "checkpoint_dir = Path(\"/kaggle/working/checkpoints\")\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "checkpoint_mgr = CheckpointManager(str(checkpoint_dir))\n",
    "\n",
    "print(\"‚úÖ Training setup complete\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Initial LR: {config.learning_rate}\")\n",
    "print(f\"   Checkpoint dir: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop\n",
    "\n",
    "**Alternating batch strategy**: MRI batch ‚Üí CT batch ‚Üí MRI batch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EPOCH {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # Alternating batch training\n",
    "    mri_iter = iter(mri_loader)\n",
    "    ct_iter = iter(ct_loader)\n",
    "    \n",
    "    steps_per_epoch = max(len(mri_loader), len(ct_loader)) * 2\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_recon = 0.0\n",
    "    epoch_contrast = 0.0\n",
    "    mri_batches = 0\n",
    "    ct_batches = 0\n",
    "    \n",
    "    progress_bar = tqdm(range(steps_per_epoch), desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    for step in progress_bar:\n",
    "        # Alternate between MRI and CT\n",
    "        if step % 2 == 0:\n",
    "            # MRI batch\n",
    "            try:\n",
    "                batch = next(mri_iter)\n",
    "                modality_name = \"MRI\"\n",
    "                mri_batches += 1\n",
    "            except StopIteration:\n",
    "                mri_iter = iter(mri_loader)\n",
    "                batch = next(mri_iter)\n",
    "                modality_name = \"MRI\"\n",
    "                mri_batches += 1\n",
    "        else:\n",
    "            # CT batch\n",
    "            try:\n",
    "                batch = next(ct_iter)\n",
    "                modality_name = \"CT\"\n",
    "                ct_batches += 1\n",
    "            except StopIteration:\n",
    "                ct_iter = iter(ct_loader)\n",
    "                batch = next(ct_iter)\n",
    "                modality_name = \"CT\"\n",
    "                ct_batches += 1\n",
    "        \n",
    "        images = batch['image'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss, loss_dict = model(images)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += total_loss.item()\n",
    "        epoch_recon += loss_dict['recon']\n",
    "        epoch_contrast += loss_dict['contrast']\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'modality': modality_name,\n",
    "            'loss': f\"{total_loss.item():.4f}\",\n",
    "            'recon': f\"{loss_dict['recon']:.4f}\",\n",
    "            'contrast': f\"{loss_dict['contrast']:.4f}\"\n",
    "        })\n",
    "    \n",
    "    # Epoch summary\n",
    "    avg_loss = epoch_loss / steps_per_epoch\n",
    "    avg_recon = epoch_recon / steps_per_epoch\n",
    "    avg_contrast = epoch_contrast / steps_per_epoch\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"  MRI batches: {mri_batches}, CT batches: {ct_batches}\")\n",
    "    print(f\"  Average Total Loss:          {avg_loss:.4f}\")\n",
    "    print(f\"  Average Reconstruction Loss: {avg_recon:.4f}\")\n",
    "    print(f\"  Average Contrastive Loss:    {avg_contrast:.4f}\")\n",
    "    print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        checkpoint_mgr.save_checkpoint(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            epoch=epoch,\n",
    "            loss=avg_loss\n",
    "        )\n",
    "        print(f\"  ‚≠ê Best model saved (loss: {best_loss:.4f})\")\n",
    "    \n",
    "    # Log history\n",
    "    history.append({\n",
    "        'epoch': epoch+1,\n",
    "        'loss': avg_loss,\n",
    "        'recon_loss': avg_recon,\n",
    "        'contrast_loss': avg_contrast,\n",
    "        'lr': optimizer.param_groups[0]['lr'],\n",
    "        'mri_batches': mri_batches,\n",
    "        'ct_batches': ct_batches\n",
    "    })\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üéâ TRAINING COMPLETED!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Best loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Save training history\n",
    "df_history = pd.DataFrame(history)\n",
    "df_history.to_csv(\"/kaggle/working/training_history.csv\", index=False)\n",
    "print(\"‚úÖ Training history saved\")\n",
    "\n",
    "# Plot loss curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Total loss\n",
    "axes[0].plot(df_history['epoch'], df_history['loss'], 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Total Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Reconstruction loss\n",
    "axes[1].plot(df_history['epoch'], df_history['recon_loss'], 'r-', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].set_title('Reconstruction Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Contrastive loss\n",
    "axes[2].plot(df_history['epoch'], df_history['contrast_loss'], 'g-', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Loss', fontsize=12)\n",
    "axes[2].set_title('Contrastive Loss', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/kaggle/working/training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Plots saved\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"  Initial loss: {df_history['loss'].iloc[0]:.4f}\")\n",
    "print(f\"  Final loss: {df_history['loss'].iloc[-1]:.4f}\")\n",
    "print(f\"  Best loss: {df_history['loss'].min():.4f}\")\n",
    "print(f\"  Loss reduction: {(1 - df_history['loss'].iloc[-1]/df_history['loss'].iloc[0])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Model\n",
    "\n",
    "Save the trained encoder for downstream tasks (Phase 1 fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full checkpoint\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'config': config.__dict__,\n",
    "    'history': history,\n",
    "    'best_loss': best_loss\n",
    "}, \"/kaggle/working/phase0_final_checkpoint.pth\")\n",
    "\n",
    "# Save encoder only (for fine-tuning)\n",
    "torch.save({\n",
    "    'waveformer_state_dict': model.waveformer.state_dict(),\n",
    "    'config': config.__dict__\n",
    "}, \"/kaggle/working/waveformer_encoder.pth\")\n",
    "\n",
    "print(\"‚úÖ Model saved\")\n",
    "print(\"\\nFiles to download:\")\n",
    "print(\"  üì¶ phase0_final_checkpoint.pth - Full training checkpoint\")\n",
    "print(\"  üß† waveformer_encoder.pth - Encoder only (for fine-tuning)\")\n",
    "print(\"  üìä training_history.csv - Training metrics\")\n",
    "print(\"  üìà training_curves.png - Loss curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook completed Phase 0 pre-training using:\n",
    "\n",
    "### Architecture\n",
    "- **Unified Multi-Modal WaveFormer**: Single model handling both MRI (1ch) and CT (3ch)\n",
    "- **Dual Patch Embedding**: Adaptive channel handling at runtime\n",
    "- **Pure SparK**: MinkowskiEngine sparse operations (NO fallback)\n",
    "\n",
    "### Pre-training Strategy\n",
    "- **MiM Hierarchical Masking**: 60% global, 80% local (adaptive block size)\n",
    "- **Spatial Contrastive Loss**: InfoNCE at same coordinates across depths\n",
    "- **Alternating Batch Training**: Equal exposure to both modalities\n",
    "\n",
    "### Data\n",
    "- **OpenMind MRI**: MRI_T1, MRI_T2, MRA (1-channel)\n",
    "- **DeepLesion CT**: 3-channel windowed (brain/blood/bone)\n",
    "- **Preprocessing**: 1mm¬≥ isotropic, RAS orientation\n",
    "\n",
    "### Next Steps\n",
    "1. Download trained encoder weights (`waveformer_encoder.pth`)\n",
    "2. Use for RSNA 2025 stroke detection fine-tuning (Phase 1)\n",
    "3. Encoder is modality-agnostic - works with any 1ch or 3ch 3D medical image\n",
    "\n",
    "---\n",
    "\n",
    "**Based on**: `source/train_phase0_subset.py` (validated implementation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
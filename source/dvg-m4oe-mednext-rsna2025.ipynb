{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"},{"sourceId":99552,"databundleVersionId":13851420,"sourceType":"competition"},{"sourceId":13281020,"sourceType":"datasetVersion","datasetId":8416865},{"sourceId":13300361,"sourceType":"datasetVersion","datasetId":8430275},{"sourceId":13300667,"sourceType":"datasetVersion","datasetId":8430500},{"sourceId":13307238,"sourceType":"datasetVersion","datasetId":8435030},{"sourceId":13319850,"sourceType":"datasetVersion","datasetId":8444045},{"sourceId":13332957,"sourceType":"datasetVersion","datasetId":8453567}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nDVG-M4oE: COMPLETE PRODUCTION CODE WITH INNOVATIONS - FIXED VERSION\n- Integrated all components: Dataset, Model, Training\n- MedNeXt backbone for feature extraction\n- Focal Loss for class imbalance handling\n- On-demand Frangi vessel mask generation if missing\n- Comprehensive checkpoint system with torch.save\n- Enhanced early stopping and metrics\n- Self-contained script ready for RSNA 2025\n\"\"\"\n\nimport sys\nimport os\nimport logging\nimport re\nfrom glob import glob\nfrom multiprocessing import Pool\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport nibabel as nib\nfrom scipy import ndimage\nfrom scipy.ndimage import distance_transform_edt\nfrom skimage.filters import frangi\nfrom skimage.morphology import remove_small_objects, skeletonize\nfrom tqdm.auto import tqdm\nimport pickle\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.optim.lr_scheduler import StepLR\nimport torch.optim as optim\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, average_precision_score\n\nimport shutil\nimport traceback\nfrom multiprocessing.dummy import Pool as ThreadPool\nfrom datetime import datetime\nimport gc\nimport copy\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ================================================================================\n# M4oE COMPONENTS\n# ================================================================================\ndef softmax(x: torch.Tensor, dim) -> torch.Tensor:\n    max_vals = torch.amax(x, dim=dim, keepdim=True)\n    e_x = torch.exp(x - max_vals)\n    sum_exp = e_x.sum(dim=dim, keepdim=True)\n    return e_x / sum_exp\n\nclass MutualInformationLoss(nn.Module):\n    def __init__(self, epsilon=1e-4):\n        super().__init__()\n        self.epsilon = epsilon\n    \n    def forward(self, phi: torch.Tensor) -> torch.Tensor:\n        batch_size, m, n, p = phi.shape\n        \n        phi = phi.reshape(phi.shape[0], phi.shape[1] * phi.shape[2] * phi.shape[3])\n        phi = torch.softmax(phi, dim=1)\n        phi = phi.reshape(phi.shape[0], m, n, p)\n        \n        p_m = phi.sum(dim=(2, 3))\n        p_t = phi.sum(dim=(1, 2))\n        p_mt = phi.sum(dim=2)\n        \n        denominator = p_m.unsqueeze(2) * p_t.unsqueeze(1)\n        numerator = p_mt\n        \n        log_term = torch.log(numerator / (denominator + 1e-10))\n        mutual_info = torch.sum(p_mt * log_term, dim=(0, 1, 2))\n        \n        return -mutual_info\n\n# ================================================================================\n# FIXED MedNeXt ENCODER IMPLEMENTATION\n# ================================================================================\nclass MedNeXtEncoder(nn.Module):\n    \"\"\"Fixed MedNeXt encoder for feature extraction\"\"\"\n    \n    def __init__(self, in_channels=1, feature_dim=512):\n        super().__init__()\n        \n        # Simplified MedNeXt-style encoder\n        self.stem = nn.Sequential(\n            nn.Conv3d(in_channels, 32, kernel_size=7, stride=2, padding=3),\n            nn.BatchNorm3d(32),\n            nn.ReLU(inplace=True)\n        )\n        \n        # Down blocks\n        self.down1 = self._make_layer(32, 64, stride=2)\n        self.down2 = self._make_layer(64, 128, stride=2) \n        self.down3 = self._make_layer(128, 256, stride=2)\n        self.down4 = self._make_layer(256, 512, stride=2)\n        \n        # Global pooling and projection\n        self.global_pool = nn.AdaptiveAvgPool3d(1)\n        self.projection = nn.Linear(512, feature_dim)\n        \n    def _make_layer(self, in_channels, out_channels, stride=1):\n        return nn.Sequential(\n            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n            nn.BatchNorm3d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm3d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    \n    def forward(self, x):\n        x = self.stem(x)\n        x = self.down1(x)\n        x = self.down2(x)\n        x = self.down3(x)\n        x = self.down4(x)\n        \n        x = self.global_pool(x)\n        x = x.flatten(1)\n        x = self.projection(x)\n        \n        return x\n\n# ================================================================================\n# BLUEPRINT STAGES\n# ================================================================================\nclass CTAAdaptiveProjection(nn.Module):\n    \"\"\"STAGE 1: CTA Adaptive Projection Layer\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.projection = nn.Conv3d(3, 1, kernel_size=1, bias=False)\n        clinical_weights = torch.tensor([0.3, 0.6, 0.1])  # [Brain, Blood, Bone]\n        self.projection.weight.data = clinical_weights.view(1, 3, 1, 1, 1)\n\n    def forward(self, cta_3channel):\n        return self.projection(cta_3channel)\n\nclass VesselGuidedAttention(nn.Module):\n    \"\"\"STAGE 3: Vessel-Guided Enhancement\"\"\"\n    def __init__(self, feature_dim=512):\n        super().__init__()\n        \n        self.spatial_attention = nn.Sequential(\n            nn.Conv3d(1, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv3d(16, 1, kernel_size=1),\n            nn.Sigmoid()\n        )\n        \n        self.vessel_to_feature = nn.Sequential(\n            nn.Linear(1, feature_dim),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, features, vessel_mask=None):\n        if vessel_mask is not None and vessel_mask.sum() > 0:\n            vessel_attention_spatial = self.spatial_attention(vessel_mask)\n            vessel_context_scalar = F.adaptive_avg_pool3d(vessel_attention_spatial, 1).flatten(1)\n            vessel_attention_features = self.vessel_to_feature(vessel_context_scalar)\n            enhanced_features = features * vessel_attention_features\n            return enhanced_features\n        else:\n            return features\n\nclass ModalitySpecificMoE(nn.Module):\n    \"\"\"Custom MSoE with vessel guidance\"\"\"\n    def __init__(self, num_experts=6, feature_dim=512):\n        super().__init__()\n        \n        self.experts = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(feature_dim, feature_dim * 2),\n                nn.ReLU(inplace=True),\n                nn.Dropout(0.1),\n                nn.Linear(feature_dim * 2, feature_dim),\n                nn.LayerNorm(feature_dim)\n            ) for _ in range(num_experts)\n        ])\n        \n        self.vessel_gating = nn.Sequential(\n            nn.Linear(feature_dim + 1, num_experts),\n            nn.Softmax(dim=-1)\n        )\n        \n    def forward(self, modality_features, vessel_context=None):\n        B = modality_features.size(0)\n        \n        if vessel_context is not None:\n            gating_input = torch.cat([modality_features, vessel_context], dim=1)\n        else:\n            zero_vessel = torch.zeros(B, 1, device=modality_features.device)\n            gating_input = torch.cat([modality_features, zero_vessel], dim=1)\n        \n        expert_weights = self.vessel_gating(gating_input)\n        \n        expert_outputs = torch.stack([\n            expert(modality_features) for expert in self.experts\n        ], dim=1)\n        \n        output = torch.sum(expert_weights.unsqueeze(-1) * expert_outputs, dim=1)\n        \n        return output, expert_weights\n\nclass CrossModalTaskMoE(nn.Module):\n    \"\"\"Cross-Modal Task MoE with routing logits extraction for CMI\"\"\"\n    def __init__(self, num_experts=8, num_tasks=14, feature_dim=512):\n        super().__init__()\n        \n        self.task_embeddings = nn.Parameter(torch.randn(num_tasks, 64) * 0.02)\n        \n        self.experts = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(feature_dim * 4, feature_dim * 2),\n                nn.ReLU(inplace=True),\n                nn.Dropout(0.1),\n                nn.Linear(feature_dim * 2, feature_dim),\n                nn.LayerNorm(feature_dim)\n            ) for _ in range(num_experts)\n        ])\n        \n        self.routing_matrix = nn.Parameter(\n            torch.zeros(feature_dim * 4, num_experts, num_tasks)\n        )\n        nn.init.normal_(self.routing_matrix, mean=0, std=1/(feature_dim * 4)**0.5)\n        \n        self.task_gating = nn.Sequential(\n            nn.Linear(feature_dim * 4 + 64, feature_dim),\n            nn.ReLU(),\n            nn.Linear(feature_dim, num_experts),\n            nn.Softmax(dim=-1)\n        )\n        \n    def forward(self, all_modality_features, task_id):\n        B = all_modality_features.size(0)\n        \n        if isinstance(task_id, int):\n            task_embedding = self.task_embeddings[task_id].unsqueeze(0).expand(B, -1)\n        else:\n            task_embedding = self.task_embeddings[task_id]\n        \n        features_seq = all_modality_features.unsqueeze(1)\n        routing_logits = torch.einsum(\"bmd,dnp->bmnp\", features_seq, self.routing_matrix)\n        \n        gating_input = torch.cat([all_modality_features, task_embedding], dim=1)\n        expert_weights = self.task_gating(gating_input)\n        \n        expert_outputs = torch.stack([\n            expert(all_modality_features) for expert in self.experts\n        ], dim=1)\n        \n        fused_output = torch.sum(expert_weights.unsqueeze(-1) * expert_outputs, dim=1)\n        \n        return fused_output, expert_weights, routing_logits\n\nclass SequentialExpertCommunication(nn.Module):\n    \"\"\"Sequential Expert Communication (Chain-of-Experts)\"\"\"\n    def __init__(self, num_experts=6, num_iterations=3, feature_dim=512):\n        super().__init__()\n        \n        self.communication_experts = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(feature_dim, feature_dim * 2),\n                nn.ReLU(inplace=True),\n                nn.Dropout(0.1),\n                nn.Linear(feature_dim * 2, feature_dim),\n                nn.LayerNorm(feature_dim)\n            ) for _ in range(num_experts)\n        ])\n        \n        self.routers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(feature_dim + 1, feature_dim // 2),\n                nn.ReLU(),\n                nn.Linear(feature_dim // 2, num_experts),\n                nn.Softmax(dim=-1)\n            ) for _ in range(num_iterations)\n        ])\n        \n    def forward(self, x, vessel_context=None):\n        B, feature_dim = x.shape\n        x_refined = x\n        \n        for iteration in range(len(self.routers)):\n            if vessel_context is not None:\n                routing_input = torch.cat([x_refined, vessel_context], dim=1)\n            else:\n                zero_context = torch.zeros(B, 1, device=x.device)\n                routing_input = torch.cat([x_refined, zero_context], dim=1)\n            \n            expert_weights = self.routers[iteration](routing_input)\n            \n            expert_outputs = torch.stack([\n                expert(x_refined) for expert in self.communication_experts\n            ], dim=1)\n            \n            expert_output = torch.sum(expert_weights.unsqueeze(-1) * expert_outputs, dim=1)\n            x_refined = expert_output + x_refined  # Residual connection\n            \n        return x_refined\n\n# ================================================================================\n# CMI LOSS COMPUTATION\n# ================================================================================\ndef compute_cmi_loss_robust(mtoe_routing_logits, modality_indicators, epsilon=1e-8):\n    \"\"\"M4oE-based CMI loss using routing logits\"\"\"\n    if mtoe_routing_logits is None:\n        return torch.tensor(0.0)\n    \n    B, seq_len, N, P = mtoe_routing_logits.shape\n    M = modality_indicators.shape[1]\n    \n    mi_loss_fn = MutualInformationLoss(epsilon=epsilon)\n    \n    routing_logits_expanded = mtoe_routing_logits.unsqueeze(1).repeat(1, M, 1, 1, 1)\n    routing_logits_modal = routing_logits_expanded.squeeze(2)\n    \n    total_cmi = 0.0\n    valid_tasks = 0\n    \n    for task_k in range(P):\n        task_routing = routing_logits_modal[:, :, :, task_k]\n        \n        modality_mask = modality_indicators.float()\n        if modality_mask.sum() == 0:\n            continue\n            \n        task_routing_masked = task_routing * modality_mask.unsqueeze(-1)\n        task_phi = task_routing_masked.unsqueeze(-1)\n        \n        try:\n            cmi_task = mi_loss_fn(task_phi)\n            if not torch.isnan(cmi_task) and not torch.isinf(cmi_task):\n                total_cmi += cmi_task\n                valid_tasks += 1\n        except:\n            continue\n    \n    if valid_tasks == 0:\n        return torch.tensor(0.0, device=mtoe_routing_logits.device)\n    \n    return total_cmi / valid_tasks\n\n# ================================================================================\n# FEATURE EXTRACTION\n# ================================================================================\nclass FeatureExtraction(nn.Module):\n    \"\"\"Feature extraction with MedNeXt encoders\"\"\"\n    def __init__(self, target_dim: int = 512):\n        super().__init__()\n        \n        self.encoders = nn.ModuleDict({\n            'cta': MedNeXtEncoder(in_channels=1, feature_dim=target_dim),\n            'mra': MedNeXtEncoder(in_channels=1, feature_dim=target_dim), \n            't1': MedNeXtEncoder(in_channels=1, feature_dim=target_dim),\n            't2': MedNeXtEncoder(in_channels=1, feature_dim=target_dim)\n        })\n        \n    def forward(self, modalities):\n        features = {}\n        for modality, data in modalities.items():\n            features[modality] = self.encoders[modality](data)\n        return features\n\n# ================================================================================\n# MAIN MODEL\n# ================================================================================\nclass DVG_M4oE_Complete_Blueprint(nn.Module):\n    \"\"\"Complete blueprint implementation with all 7 stages\"\"\"\n    def __init__(self, num_classes=14, feature_dim=512):\n        super().__init__()\n        \n        self.num_classes = num_classes\n        \n        # Stage 1: CTA adaptive projection\n        self.cta_projection = CTAAdaptiveProjection()\n        \n        # Stage 2: Feature extraction\n        self.feature_extraction = FeatureExtraction(target_dim=feature_dim)\n        \n        # Stage 3: Vessel-guided attention\n        self.vessel_attention = VesselGuidedAttention(feature_dim)\n        \n        # Stage 4: MSoE processing\n        self.msoe_modules = nn.ModuleDict({\n            modality: ModalitySpecificMoE(num_experts=6, feature_dim=feature_dim)\n            for modality in ['cta', 'mra', 't1', 't2']\n        })\n        \n        # Stage 6: Sequential expert communication\n        self.expert_communication = SequentialExpertCommunication(\n            num_experts=6, num_iterations=3, feature_dim=feature_dim\n        )\n        \n        # Stage 5: MToE processing  \n        self.mtoe_module = CrossModalTaskMoE(\n            num_experts=8, num_tasks=num_classes, feature_dim=feature_dim\n        )\n        \n        # Stage 7: Task-specific classification heads\n        self.task_heads = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(feature_dim, feature_dim // 2),\n                nn.ReLU(),\n                nn.Dropout(0.1),\n                nn.Linear(feature_dim // 2, 1)\n            ) for _ in range(num_classes)\n        ])\n        \n        # Missing modality handling\n        self.missing_modality_embedding = nn.Parameter(torch.randn(feature_dim) * 0.02)\n    \n    def forward(self, batch):\n        B = batch['cta'].size(0)\n        \n        # Stage 1: CTA adaptive projection\n        cta_processed = self.cta_projection(batch['cta'])\n        \n        # Prepare modalities\n        modalities = {\n            'cta': cta_processed,\n            'mra': batch['mra'],\n            't1': batch['t1'], \n            't2': batch['t2']\n        }\n        \n        # Stage 2: Feature extraction\n        features = self.feature_extraction(modalities)\n        \n        # Handle missing modalities\n        for modality in features:\n            if features[modality].sum() == 0:\n                features[modality] = self.missing_modality_embedding.unsqueeze(0).expand(B, -1)\n        \n        # Stage 3: Vessel-guided enhancement\n        vessel_mask = batch.get('vessel_mask', None)\n        enhanced_features = {}\n        \n        for mod, feat in features.items():\n            enhanced_features[mod] = self.vessel_attention(feat, vessel_mask)\n\n        # Vessel context\n        vessel_context = None\n        if vessel_mask is not None and vessel_mask.sum() > 0:\n            vessel_context = F.adaptive_avg_pool3d(vessel_mask, 1).flatten(1)\n        else:\n            vessel_context = torch.zeros(B, 1, device=batch['cta'].device)\n        \n        # Stage 4: MSoE processing\n        msoe_outputs = {}\n        msoe_weights = {}\n        \n        for modality, feat in enhanced_features.items():\n            msoe_out, exp_weights = self.msoe_modules[modality](feat, vessel_context)\n            msoe_outputs[modality] = msoe_out\n            msoe_weights[f'msoe_{modality}'] = exp_weights\n        \n        # Stage 6: Sequential expert communication\n        communicated_outputs = {}\n        for modality, msoe_out in msoe_outputs.items():\n            communicated_outputs[modality] = self.expert_communication(\n                msoe_out, vessel_context\n            )\n        \n        # Stage 5: MToE cross-modal fusion + classification\n        all_features = torch.cat(list(communicated_outputs.values()), dim=1)\n        \n        predictions = []\n        mtoe_expert_weights = []\n        mtoe_routing_logits = []\n        \n        for task_id in range(self.num_classes):\n            task_features, task_exp_weights, task_routing_logits = self.mtoe_module(all_features, task_id)\n            prediction = self.task_heads[task_id](task_features)\n            \n            predictions.append(prediction)\n            mtoe_expert_weights.append(task_exp_weights)\n            mtoe_routing_logits.append(task_routing_logits)\n        \n        predictions = torch.cat(predictions, dim=-1)\n        stacked_routing_logits = torch.cat(mtoe_routing_logits, dim=-1)\n        \n        return {\n            'predictions': predictions,\n            'msoe_weights': msoe_weights,\n            'mtoe_weights': torch.stack(mtoe_expert_weights, dim=1),\n            'mtoe_routing_logits': stacked_routing_logits,\n            'features': communicated_outputs\n        }\n\n# ================================================================================\n# FOCAL LOSS\n# ================================================================================\nclass FocalLoss(nn.Module):\n    \"\"\"Focal loss for class imbalance\"\"\"\n    \n    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n        super().__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n    \n    def forward(self, input, target):\n        ce_loss = F.binary_cross_entropy_with_logits(input, target, reduction='none')\n        pt = torch.exp(-ce_loss)\n        f_loss = (1 - pt) ** self.gamma * ce_loss\n        \n        if self.alpha is not None:\n            f_loss = self.alpha * f_loss\n        \n        if self.reduction == 'mean':\n            return f_loss.mean()\n        elif self.reduction == 'sum':\n            return f_loss.sum()\n        return f_loss\n\n# ================================================================================\n# LOSS COMPUTATION\n# ================================================================================\ndef compute_total_loss_corrected(predictions, targets, model_outputs, modality_indicators, beta=0.1, focal_gamma=2.0):\n    \"\"\"Corrected loss computation with Focal Loss\"\"\"\n    focal_loss = FocalLoss(gamma=focal_gamma)\n    classification_loss = focal_loss(predictions, targets)\n    \n    if 'mtoe_routing_logits' in model_outputs:\n        cmi_loss = compute_cmi_loss_robust(\n            model_outputs['mtoe_routing_logits'],\n            modality_indicators\n        )\n    else:\n        cmi_loss = torch.tensor(0.0)\n    \n    total_loss = classification_loss - beta * cmi_loss\n    \n    return {\n        'total_loss': total_loss,\n        'classification_loss': classification_loss,\n        'cmi_loss': cmi_loss\n    }\n\n# ================================================================================\n# METRICS CLASS\n# ================================================================================\nclass ProductionMetricsFixed:\n    \"\"\"Production metrics for RSNA tasks\"\"\"\n    def __init__(self, task_names, short_names):\n        self.task_names = task_names\n        self.short_names = short_names\n        self.reset()\n    \n    def reset(self):\n        self.predictions = []\n        self.targets = []\n        self.losses = []\n        self.classification_losses = []\n        self.cmi_losses = []\n        self.batch_times = []\n        self.learning_rates = []\n    \n    def update(self, predictions, targets, total_loss, class_loss, cmi_loss, batch_time, lr=None):\n        self.predictions.append(predictions.detach().cpu())\n        self.targets.append(targets.detach().cpu())\n        self.losses.append(total_loss.detach().cpu().item())\n        self.classification_losses.append(class_loss.detach().cpu().item())\n        self.cmi_losses.append(cmi_loss.detach().cpu().item() if isinstance(cmi_loss, torch.Tensor) else cmi_loss)\n        self.batch_times.append(batch_time)\n        if lr is not None:\n            self.learning_rates.append(lr)\n    \n    def compute_rsna_metrics(self):\n        if not self.predictions:\n            return {}\n        \n        all_preds = torch.cat(self.predictions, dim=0).numpy()\n        all_targets = torch.cat(self.targets, dim=0).numpy()\n        \n        # Compute AUC for each task\n        task_aucs = {}\n        valid_aucs = []\n        \n        for i, task_name in enumerate(self.short_names):\n            try:\n                if len(np.unique(all_targets[:, i])) > 1:\n                    auc = roc_auc_score(all_targets[:, i], all_preds[:, i])\n                    task_aucs[task_name] = auc\n                    valid_aucs.append(auc)\n                else:\n                    task_aucs[task_name] = 0.5\n            except:\n                task_aucs[task_name] = 0.5\n        \n        mean_auc = np.mean(valid_aucs) if valid_aucs else 0.5\n        aneurysm_auc = task_aucs.get('Aneurysm', 0.5)\n        \n        return {\n            'loss': np.mean(self.losses),\n            'classification_loss': np.mean(self.classification_losses),\n            'cmi_loss': np.mean(self.cmi_losses),\n            'mean_auc': mean_auc,\n            'aneurysm_auc': aneurysm_auc,\n            'task_aucs': task_aucs,\n            'samples_per_sec': len(self.batch_times) / sum(self.batch_times) if self.batch_times else 0,\n            'learning_rate': self.learning_rates[-1] if self.learning_rates else 0\n        }\n\n# ================================================================================\n# CHECKPOINT MANAGER\n# ================================================================================\nclass CheckpointManager:\n    \"\"\"Comprehensive checkpoint manager\"\"\"\n    def __init__(self, config):\n        self.config = config\n        self.checkpoint_dir = Path(config['checkpoint_dir'])\n        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n        self.model_name = config['model_name']\n    \n    def save_checkpoint(self, model, optimizer, scheduler, scaler, epoch, train_results, val_results, history, config, checkpoint_type=\"latest\", extra_info=\"\"):\n        if not self.config['save_checkpoints']:\n            return None\n        \n        # Prepare checkpoint data\n        checkpoint_data = {\n            'epoch': epoch,\n            'model_state_dict': model.state_dict() if self.config['save_model_state'] else None,\n            'optimizer_state_dict': optimizer.state_dict() if self.config['save_optimizer_state'] else None,\n            'scheduler_state_dict': scheduler.state_dict() if self.config['save_scheduler_state'] else None,\n            'train_results': train_results,\n            'val_results': val_results,\n            'config': config if self.config['save_config'] else None,\n            'timestamp': datetime.now().isoformat(),\n            'checkpoint_type': checkpoint_type\n        }\n        \n        if scaler and self.config['save_scaler_state']:\n            checkpoint_data['scaler_state_dict'] = scaler.state_dict()\n        \n        if self.config['save_training_history']:\n            checkpoint_data['training_history'] = history\n        \n        # Generate filename\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        if extra_info:\n            filename = f\"{self.model_name}_{checkpoint_type}_{extra_info}_{timestamp}.pt\"\n        else:\n            filename = f\"{self.model_name}_{checkpoint_type}_{timestamp}.pt\"\n        \n        filepath = self.checkpoint_dir / filename\n        \n        # Save checkpoint\n        torch.save(checkpoint_data, filepath)\n        print(f\"ðŸ’¾ Saved {checkpoint_type} checkpoint: {filename}\")\n        \n        return filepath\n    \n    def save_latest_checkpoint(self, model, optimizer, scheduler, scaler, epoch, train_results, val_results, history, config):\n        return self.save_checkpoint(model, optimizer, scheduler, scaler, epoch, train_results, val_results, history, config, \"latest\")\n    \n    def save_best_checkpoint(self, model, optimizer, scheduler, scaler, epoch, train_results, val_results, history, config):\n        return self.save_checkpoint(model, optimizer, scheduler, scaler, epoch, train_results, val_results, history, config, \"best\")\n    \n    def save_periodic_checkpoint(self, model, optimizer, scheduler, scaler, epoch, train_results, val_results, history, config):\n        if (epoch + 1) % self.config['periodic_epochs'] == 0:\n            return self.save_checkpoint(model, optimizer, scheduler, scaler, epoch, train_results, val_results, history, config, \"periodic\", f\"epoch_{epoch+1}\")\n        return None\n    \n    def save_final_checkpoint(self, model, optimizer, scheduler, scaler, epoch, train_results, val_results, history, config, stop_reason=\"\"):\n        extra = f\"final_{stop_reason}\" if stop_reason else \"final\"\n        return self.save_checkpoint(model, optimizer, scheduler, scaler, epoch, train_results, val_results, history, config, \"final\", extra)\n    \n    def get_checkpoint_summary(self):\n        checkpoints = list(self.checkpoint_dir.glob(f\"{self.model_name}_*.pt\"))\n        return {\n            'checkpoint_dir': str(self.checkpoint_dir),\n            'total_checkpoints': len(checkpoints),\n            'best_checkpoint': str(next((f for f in checkpoints if 'best' in f.name), 'None')),\n            'latest_checkpoint': str(next((f for f in checkpoints if 'latest' in f.name), 'None'))\n        }\n\n# ================================================================================\n# ENHANCED EARLY STOPPING\n# ================================================================================\nclass EnhancedEarlyStopping:\n    \"\"\"Enhanced early stopping with multiple criteria\"\"\"\n    def __init__(self, config):\n        self.primary_metric = config['primary_metric']\n        self.primary_mode = config['primary_mode']\n        self.primary_patience = config['primary_patience']\n        self.primary_min_delta = config['primary_min_delta']\n        \n        self.best_primary_score = float('-inf') if self.primary_mode == 'max' else float('inf')\n        self.primary_patience_counter = 0\n        self.best_epoch = -1\n        self.best_model_state = None\n        \n        self.epochs_no_improvement = 0\n        self.max_epochs_no_improvement = config.get('max_epochs_no_improvement', 8)\n        \n    def step(self, epoch, val_results, model, optimizer):\n        current_score = val_results.get(self.primary_metric, 0.0)\n        \n        # Check if improved\n        if self.primary_mode == 'max':\n            improved = current_score > (self.best_primary_score + self.primary_min_delta)\n        else:\n            improved = current_score < (self.best_primary_score - self.primary_min_delta)\n        \n        if improved:\n            self.best_primary_score = current_score\n            self.primary_patience_counter = 0\n            self.epochs_no_improvement = 0\n            self.best_epoch = epoch\n            self.best_model_state = copy.deepcopy(model.state_dict())\n        else:\n            self.primary_patience_counter += 1\n            self.epochs_no_improvement += 1\n        \n        # Check stopping conditions\n        should_stop = False\n        stop_reason = \"\"\n        \n        if self.primary_patience_counter >= self.primary_patience:\n            should_stop = True\n            stop_reason = f\"Primary metric ({self.primary_metric}) patience exceeded\"\n        elif self.epochs_no_improvement >= self.max_epochs_no_improvement:\n            should_stop = True\n            stop_reason = f\"No improvement for {self.max_epochs_no_improvement} epochs\"\n        \n        return should_stop, stop_reason, improved\n    \n    def restore_best_model(self, model, optimizer):\n        if self.best_model_state is not None:\n            model.load_state_dict(self.best_model_state)\n            return True\n        return False\n    \n    def get_status_info(self):\n        return {\n            'primary_patience': f\"{self.primary_patience_counter}/{self.primary_patience}\",\n            'primary_best': f\"{self.best_primary_score:.4f}\",\n            'epochs_no_improvement': self.epochs_no_improvement,\n            'best_epoch': self.best_epoch\n        }\n\n# ================================================================================\n# DATASET\n# ================================================================================\nclass DVG_MultiModalRSNADataset(Dataset):\n    \"\"\"DVG-M4oE optimized dataset with Frangi vessel generation if missing\"\"\"\n    \n    def __init__(self, \n                 csv_path: str, \n                 data_root: str,\n                 clean_files_path: Optional[str] = None,\n                 split: str = 'train', \n                 train_ratio: float = 0.8,\n                 target_size: Tuple[int, int, int] = (128, 128, 128),\n                 verbose: bool = True,\n                 debug_first_sample: bool = True):\n        \n        self.data_root = Path(data_root)\n        self.split = split\n        self.target_size = target_size\n        self.verbose = verbose\n        self.debug_first_sample = debug_first_sample\n        self.first_sample_loaded = False\n        \n        # Kaggle dataset structure\n        self.csv_root = self.data_root / \"rsna-csv\"\n        self.cta1_root = self.data_root / \"rsna-cta1\" / \"CTA1\" \n        self.cta2_root = self.data_root / \"rsna-cta2\" / \"CTA\"\n        self.remains_root = self.data_root / \"rsna-remains\"\n        self.clean_files_root = self.data_root / \"rsna-clean-files\"\n        \n        # Load clean files\n        self.valid_files = None\n        clean_file_candidates = [\n            Path(clean_files_path) if clean_files_path else None,\n            self.clean_files_root / \"clean_files_kaggle.txt\",\n            self.data_root / \"clean_files_kaggle.txt\",\n        ]\n        \n        for clean_candidate in clean_file_candidates:\n            if clean_candidate and clean_candidate.exists():\n                with open(clean_candidate, 'r') as f:\n                    self.valid_files = set(line.strip() for line in f if line.strip())\n                if self.verbose:\n                    print(f\"âœ… Loaded {len(self.valid_files)} clean files\")\n                break\n        \n        # Load CSV\n        csv_candidates = [\n            Path(csv_path),\n            self.csv_root / \"train.csv\",\n        ]\n        \n        df = None\n        for csv_candidate in csv_candidates:\n            if csv_candidate.exists():\n                df = pd.read_csv(csv_candidate)\n                if self.verbose:\n                    print(f\"âœ… Loaded CSV: {csv_candidate}\")\n                break\n        \n        if df is None:\n            raise FileNotFoundError(f\"Could not find train.csv\")\n        \n        # Filter by CTA modality\n        if 'Modality' in df.columns:\n            cta_df = df[df['Modality'] == 'CTA'].reset_index(drop=True)\n        else:\n            cta_df = df.copy()\n        \n        # Apply clean file filtering\n        if self.valid_files:\n            original_len = len(cta_df)\n            cta_df = cta_df[cta_df['SeriesInstanceUID'].apply(\n                lambda uid: self._is_series_in_clean_files(uid)\n            )].reset_index(drop=True)\n        \n        # Train/val split\n        n_train = int(len(cta_df) * train_ratio)\n        if split == 'train':\n            self.df = cta_df.iloc[:n_train].reset_index(drop=True)\n        else:\n            self.df = cta_df.iloc[n_train:].reset_index(drop=True)\n        \n        self.full_df = df\n        \n        # Labels\n        self.label_cols = [\n            'Left Infraclinoid Internal Carotid Artery',\n            'Right Infraclinoid Internal Carotid Artery',\n            'Left Supraclinoid Internal Carotid Artery', \n            'Right Supraclinoid Internal Carotid Artery',\n            'Left Middle Cerebral Artery',\n            'Right Middle Cerebral Artery',\n            'Anterior Communicating Artery',\n            'Left Anterior Cerebral Artery',\n            'Right Anterior Cerebral Artery',\n            'Left Posterior Communicating Artery',\n            'Right Posterior Communicating Artery',\n            'Basilar Tip',\n            'Other Posterior Circulation',\n            'Aneurysm Present'\n        ]\n    \n    def _is_series_in_clean_files(self, series_uid: str) -> bool:\n        if self.valid_files is None:\n            return True\n        possible_formats = [\n            f\"CTA/{series_uid}.nii.gz\",\n            f\"CTA/{series_uid}.nii\",\n            f\"MRA/{series_uid}.nii.gz\",\n            f\"MRA/{series_uid}.nii\",\n            series_uid\n        ]\n        return any(fmt in self.valid_files for fmt in possible_formats)\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def find_file_with_extensions(self, base_path: Path, series_uid: str, \n                                   possible_extensions: List[str] = ['.nii.gz', '.nii']) -> Optional[Path]:\n        for ext in possible_extensions:\n            file_path = base_path / f\"{series_uid}{ext}\"\n            if file_path.exists():\n                return file_path\n        return None\n    \n    def find_cta_file(self, series_uid: str) -> Optional[Path]:\n        cta_bases = [self.cta1_root, self.cta2_root]\n        for base in cta_bases:\n            found = self.find_file_with_extensions(base, series_uid)\n            if found:\n                return found\n        return None\n    \n    def load_and_resize_volume_128(self, nifti_path: Optional[Path], \n                                   expected_channels: int = 1) -> torch.Tensor:\n        if nifti_path is None or not nifti_path.exists():\n            return torch.zeros(expected_channels, *self.target_size, dtype=torch.float32)\n\n        try:\n            nifti_img = nib.load(str(nifti_path))\n            volume = nifti_img.get_fdata().astype(np.float32)\n\n            # Handle shapes\n            if volume.ndim == 5:\n                if volume.shape[-1] == 3:\n                    volume = volume[..., 0, :].transpose(3, 0, 1, 2)\n                else:\n                    volume = volume[..., 0, 0][np.newaxis, ...]\n                    \n            elif volume.ndim == 4:\n                if volume.shape[-1] == 3:\n                    volume = volume.transpose(3, 0, 1, 2)\n                elif volume.shape[-1] == 1:\n                    volume = volume[..., 0][np.newaxis, ...]\n                    \n            elif volume.ndim == 3:\n                volume = volume[np.newaxis, ...]\n\n            # Ensure correct channels\n            current_channels = volume.shape[0]\n            if current_channels != expected_channels:\n                if expected_channels == 1 and current_channels >= 1:\n                    volume = volume[0:1, ...]\n                elif expected_channels == 3:\n                    if current_channels == 1:\n                        volume = np.repeat(volume, 3, axis=0)\n                    elif current_channels >= 3:\n                        volume = volume[:3, ...]\n\n            # Resize to 128Â³\n            volume_tensor = torch.from_numpy(volume).unsqueeze(0).float()\n            volume_resized = torch.nn.functional.interpolate(\n                volume_tensor,\n                size=self.target_size,\n                mode='trilinear',\n                align_corners=False\n            )\n\n            result = volume_resized.squeeze(0)\n            return result\n\n        except Exception as e:\n            return torch.zeros(expected_channels, *self.target_size, dtype=torch.float32)\n    \n    def find_related_series(self, cta_series_uid: str, modality_folder: Path) -> Optional[Path]:\n        # Strategy 1: Direct SeriesUID match\n        direct_match = self.find_file_with_extensions(modality_folder, cta_series_uid)\n        if direct_match:\n            return direct_match\n        \n        # Strategy 2: Find via patient matching\n        if hasattr(self, 'full_df'):\n            cta_row = self.full_df[self.full_df['SeriesInstanceUID'] == cta_series_uid]\n            if not cta_row.empty:\n                cta_row = cta_row.iloc[0]\n                patient_age = cta_row.get('PatientAge', None)\n                patient_sex = cta_row.get('PatientSex', None)\n                \n                modality_name_map = {\n                    'MRA': 'MRA',\n                    'MRI_T1post': 'MRI T1post',\n                    'MRI_T2': 'MRI T2'\n                }\n                target_modality = None\n                for folder_name, csv_modality in modality_name_map.items():\n                    if folder_name in str(modality_folder):\n                        target_modality = csv_modality\n                        break\n                \n                if target_modality and patient_age is not None:\n                    candidate_rows = self.full_df[\n                        (self.full_df['Modality'] == target_modality) &\n                        (self.full_df['PatientAge'] == patient_age) &\n                        (self.full_df['PatientSex'] == patient_sex)\n                    ]\n                    \n                    for _, candidate_row in candidate_rows.iterrows():\n                        candidate_uid = candidate_row['SeriesInstanceUID']\n                        candidate_path = self.find_file_with_extensions(modality_folder, candidate_uid)\n                        if candidate_path and candidate_path.exists():\n                            return candidate_path\n        \n        return None\n    \n    def generate_vessel_mask_frangi(self, volume: torch.Tensor) -> torch.Tensor:\n        \"\"\"Generate vessel mask using Frangi if missing\"\"\"\n        vol_np = volume.squeeze().cpu().numpy()\n        vol_enh = frangi(vol_np, sigmas=(1, 5), scale_step=1)\n        mask = vol_enh > np.percentile(vol_enh, 95)\n        mask = remove_small_objects(mask, min_size=100)\n        return torch.from_numpy(mask.astype(np.float32)).unsqueeze(0)\n    \n    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n        row = self.df.iloc[idx]\n        series_uid = row['SeriesInstanceUID']\n        \n        # Load CTA\n        cta_path = self.find_cta_file(series_uid)\n        cta = self.load_and_resize_volume_128(cta_path, expected_channels=3)\n\n        # Load other modalities\n        mra_path = self.find_related_series(series_uid, self.remains_root / 'MRA')\n        mra = self.load_and_resize_volume_128(mra_path, expected_channels=1)\n        \n        t1_path = self.find_related_series(series_uid, self.remains_root / 'MRI_T1post')\n        t1 = self.load_and_resize_volume_128(t1_path, expected_channels=1)\n        \n        t2_path = self.find_related_series(series_uid, self.remains_root / 'MRI_T2')\n        t2 = self.load_and_resize_volume_128(t2_path, expected_channels=1)\n        \n        # Vessel mask - try to find or generate with Frangi\n        vessel_mask_path = self.find_file_with_extensions(\n            self.remains_root / 'vessel_masks', \n            f\"{series_uid}_vessel_mask\"\n        )\n        vessel_mask = self.load_and_resize_volume_128(vessel_mask_path, expected_channels=1)\n        \n        if vessel_mask.sum() == 0:\n            vessel_mask = self.generate_vessel_mask_frangi(cta.mean(0, keepdim=True))\n\n        # Modality indicators\n        modality_indicators = torch.tensor([\n            1.0 if cta.sum() > 0 else 0.0,\n            1.0 if mra.sum() > 0 else 0.0,\n            1.0 if t1.sum() > 0 else 0.0,\n            1.0 if t2.sum() > 0 else 0.0\n        ], dtype=torch.float32)\n\n        # Labels\n        labels = []\n        for col in self.label_cols:\n            if col in row and pd.notna(row[col]):\n                labels.append(float(row[col]))\n            else:\n                labels.append(0.0)\n        labels = torch.tensor(labels, dtype=torch.float32)\n\n        # Metadata\n        metadata = {\n            'age': float(row.get('PatientAge', 0.0)),\n            'sex': 1.0 if row.get('PatientSex', 'Unknown') == 'Male' else 0.0,\n            'series_uid': series_uid,\n            'modality_count': int(modality_indicators.sum().item()),\n            'has_vessel_mask': 1.0 if vessel_mask.sum() > 0 else 0.0\n        }\n\n        return {\n            'cta': cta,\n            'mra': mra,\n            't1': t1,\n            't2': t2,\n            'vessel_mask': vessel_mask,\n            'labels': labels,\n            'modality_indicators': modality_indicators,\n            'metadata': metadata\n        }\n\ndef dvg_collate_fn(batch: List[Dict]) -> Dict[str, torch.Tensor]:\n    \"\"\"Custom collate function\"\"\"\n    keys = batch[0].keys()\n    collated = {}\n    \n    for key in keys:\n        if key == 'metadata':\n            collated[key] = [sample[key] for sample in batch]\n        else:\n            collated[key] = torch.stack([sample[key] for sample in batch], dim=0)\n    \n    return collated\n\n# ================================================================================\n# HELPER FUNCTIONS\n# ================================================================================\ndef create_dvg_m4oe_complete_blueprint(device: str = \"cuda:0\", num_gpus: int = 4, **kwargs):\n    \"\"\"Create DVG-M4oE model\"\"\"\n    model = DVG_M4oE_Complete_Blueprint(**kwargs)\n    model = model.to(device)\n    \n    if num_gpus > 1:\n        model = nn.DataParallel(model, device_ids=list(range(num_gpus)))\n    \n    return model\n\ndef get_dvg_dataloaders(\n    csv_path: str = \"/kaggle/input/rsna-csv/train.csv\",\n    data_root: str = \"/kaggle/input\",\n    clean_files_path: Optional[str] = \"/kaggle/input/rsna-clean-files/clean_files_kaggle.txt\",\n    batch_size: int = 4,\n    num_workers: int = 4,\n    target_size: Tuple[int, int, int] = (128, 128, 128),\n    train_ratio: float = 0.8,\n    verbose: bool = True,\n    debug_first_sample: bool = True\n) -> Tuple[DataLoader, DataLoader]:\n    \n    train_dataset = DVG_MultiModalRSNADataset(\n        csv_path=csv_path,\n        data_root=data_root,\n        clean_files_path=clean_files_path,\n        split='train',\n        target_size=target_size,\n        verbose=verbose,\n        debug_first_sample=debug_first_sample\n    )\n    \n    val_dataset = DVG_MultiModalRSNADataset(\n        csv_path=csv_path,\n        data_root=data_root,\n        clean_files_path=clean_files_path,\n        split='val',\n        target_size=target_size,\n        verbose=verbose,\n        debug_first_sample=False\n    )\n\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True,\n        drop_last=True,\n        collate_fn=dvg_collate_fn,\n        persistent_workers=True if num_workers > 0 else False\n    )\n\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True,\n        collate_fn=dvg_collate_fn,\n        persistent_workers=True if num_workers > 0 else False\n    )\n\n    return train_loader, val_loader\n\n# ================================================================================\n# CONFIGURATION CLASS\n# ================================================================================\nclass ProductionConfigFixed:\n    \"\"\"Production configuration with innovations\"\"\"\n    \n    def __init__(self):\n        # Data paths\n        self.csv_path = \"/kaggle/input/rsna-csv/train.csv\"\n        self.data_root = \"/kaggle/input\"\n        self.clean_files_path = \"/kaggle/input/rsna-clean-files/clean_files_kaggle.txt\"\n        \n        # Training parameters\n        self.num_epochs = 20\n        self.batch_size = 4\n        self.learning_rate = 1e-5\n        self.weight_decay = 1e-4\n        \n        # Data loading\n        self.num_workers = os.cpu_count()\n        self.pin_memory = True\n        \n        # Model parameters\n        self.num_classes = 14\n        self.feature_dim = 512\n        \n        # Training optimization\n        self.grad_clip_norm = 1.0\n        self.cmi_loss_weight = 0.1\n        self.mixed_precision = True\n        self.memory_cleanup_freq = 50\n        \n        # Focal loss parameters\n        self.focal_gamma = 2.0\n        self.focal_alpha = None\n        \n        # Checkpoint configuration\n        self.checkpoint_config = {\n            'save_checkpoints': True,\n            'checkpoint_dir': '/kaggle/working/checkpoints',\n            'model_name': 'DVG_M4oE_RSNA2025',\n            'save_best_model': True,\n            'save_latest_model': True,\n            'save_final_model': True,\n            'save_periodic': True,\n            'periodic_epochs': 5,\n            'save_model_state': True,\n            'save_optimizer_state': True,\n            'save_scheduler_state': True,\n            'save_scaler_state': True,\n            'save_training_history': True,\n            'save_config': True,\n        }\n        \n        # Early stopping configuration\n        self.early_stopping_config = {\n            'primary_metric': 'mean_auc',\n            'primary_mode': 'max',\n            'primary_patience': 5,\n            'primary_min_delta': 1e-4,\n            'max_epochs_no_improvement': 8,\n        }\n        \n        # RSNA task names\n        self.rsna_task_names = [\n            'Left Infraclinoid Internal Carotid Artery',\n            'Right Infraclinoid Internal Carotid Artery', \n            'Left Supraclinoid Internal Carotid Artery',\n            'Right Supraclinoid Internal Carotid Artery',\n            'Left Middle Cerebral Artery',\n            'Right Middle Cerebral Artery',\n            'Anterior Communicating Artery',\n            'Left Anterior Cerebral Artery', \n            'Right Anterior Cerebral Artery',\n            'Left Posterior Communicating Artery',\n            'Right Posterior Communicating Artery',\n            'Basilar Tip',\n            'Other Posterior Circulation',\n            'Aneurysm Present'\n        ]\n        \n        self.task_short_names = [\n            'L_Infra_ICA', 'R_Infra_ICA', 'L_Supra_ICA', 'R_Supra_ICA',\n            'L_MCA', 'R_MCA', 'AComA', 'L_ACA', 'R_ACA', \n            'L_PComA', 'R_PComA', 'Basilar', 'Other_Post', 'Aneurysm'\n        ]\n\n# ================================================================================\n# TRAINER CLASS\n# ================================================================================\nclass ProductionTrainerFixed:\n    \"\"\"Production trainer with innovations integrated\"\"\"\n    \n    def __init__(self, config: ProductionConfigFixed):\n        self.config = config\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.num_gpus = torch.cuda.device_count()\n        \n        # GPU optimizations\n        if torch.cuda.is_available():\n            torch.backends.cudnn.benchmark = True\n            torch.backends.cuda.matmul.allow_tf32 = True\n            torch.backends.cudnn.allow_tf32 = True\n        \n        # Create model\n        self.model = create_dvg_m4oe_complete_blueprint(\n            device=self.device,\n            num_gpus=self.num_gpus,\n            num_classes=config.num_classes,\n            feature_dim=config.feature_dim\n        )\n        \n        if isinstance(self.model, nn.DataParallel):\n            self.base_model = self.model.module\n        else:\n            self.base_model = self.model\n        \n        # Create optimizer\n        self.optimizer = optim.AdamW(\n            self.model.parameters(),\n            lr=config.learning_rate,\n            weight_decay=config.weight_decay\n        )\n        \n        # Scheduler\n        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, \n            T_0=5,\n            T_mult=2,\n            eta_min=1e-6\n        )\n        \n        # Mixed precision\n        self.scaler = GradScaler() if config.mixed_precision else None\n        \n        # Metrics\n        self.train_metrics = ProductionMetricsFixed(config.rsna_task_names, config.task_short_names)\n        self.val_metrics = ProductionMetricsFixed(config.rsna_task_names, config.task_short_names)\n        \n        # Checkpoint manager\n        self.checkpoint_manager = CheckpointManager(config.checkpoint_config)\n        \n        # Early stopping\n        self.early_stopping = EnhancedEarlyStopping(config.early_stopping_config)\n        \n        # Training state\n        self.training_history = []\n        self.start_time = None\n    \n    def _create_modality_indicators(self, batch):\n        \"\"\"Create modality indicators\"\"\"\n        B = batch['cta'].size(0)\n        device = batch['cta'].device\n        \n        modality_indicators = torch.ones(B, 4, device=device, dtype=torch.float32)\n        \n        for i, modality in enumerate(['mra', 't1', 't2']):\n            if modality in batch:\n                modality_sum = batch[modality].sum(dim=(1,2,3,4))\n                modality_indicators[:, i+1] = (modality_sum > 0.01).float()\n        \n        return modality_indicators\n    \n    def train_epoch(self, train_loader, epoch):\n        \"\"\"Training epoch\"\"\"\n        self.model.train()\n        self.train_metrics.reset()\n        \n        pbar = tqdm(\n            enumerate(train_loader), \n            total=len(train_loader),\n            desc=f\"ðŸš€ Epoch {epoch+1}\",\n            ncols=140\n        )\n        \n        for batch_idx, batch in pbar:\n            batch_start = time.time()\n            \n            # Move to device\n            for key in batch:\n                if isinstance(batch[key], torch.Tensor):\n                    batch[key] = batch[key].to(self.device)\n            \n            modality_indicators = self._create_modality_indicators(batch)\n            self.optimizer.zero_grad()\n            \n            # Forward pass\n            if self.config.mixed_precision and self.scaler:\n                with autocast():\n                    outputs = self.model(batch)\n                    loss_dict = compute_total_loss_corrected(\n                        outputs['predictions'], batch['labels'], outputs, \n                        modality_indicators, beta=self.config.cmi_loss_weight,\n                        focal_gamma=self.config.focal_gamma\n                    )\n                \n                self.scaler.scale(loss_dict['total_loss']).backward()\n                \n                if self.config.grad_clip_norm > 0:\n                    self.scaler.unscale_(self.optimizer)\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_clip_norm)\n                \n                self.scaler.step(self.optimizer)\n                self.scaler.update()\n            else:\n                outputs = self.model(batch)\n                loss_dict = compute_total_loss_corrected(\n                    outputs['predictions'], batch['labels'], outputs, \n                    modality_indicators, beta=self.config.cmi_loss_weight,\n                    focal_gamma=self.config.focal_gamma\n                )\n                \n                loss_dict['total_loss'].backward()\n                \n                if self.config.grad_clip_norm > 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_clip_norm)\n                \n                self.optimizer.step()\n            \n            batch_time = time.time() - batch_start\n            current_lr = self.optimizer.param_groups[0]['lr']\n            \n            # Update metrics\n            self.train_metrics.update(\n                outputs['predictions'], batch['labels'],\n                loss_dict['total_loss'], loss_dict['classification_loss'], loss_dict['cmi_loss'],\n                batch_time, current_lr\n            )\n            \n            # Update progress bar\n            if batch_idx % 10 == 0:\n                pbar.set_postfix({\n                    'Loss': f\"{loss_dict['total_loss'].item():.4f}\",\n                    'Class': f\"{loss_dict['classification_loss'].item():.4f}\",\n                    'CMI': f\"{loss_dict['cmi_loss'].item():.3f}\",\n                    'LR': f\"{current_lr:.2e}\",\n                    'Speed': f\"{self.config.batch_size/batch_time:.1f}sps\"\n                })\n            \n            # Memory cleanup\n            if batch_idx % self.config.memory_cleanup_freq == 0:\n                torch.cuda.empty_cache()\n        \n        pbar.close()\n        return self.train_metrics.compute_rsna_metrics()\n    \n    def validate_epoch(self, val_loader, epoch):\n        \"\"\"Validation epoch\"\"\"\n        self.model.eval()\n        self.val_metrics.reset()\n        \n        pbar = tqdm(\n            val_loader,\n            desc=f\"ðŸ“Š Validation {epoch+1}\",\n            ncols=120\n        )\n        \n        with torch.no_grad():\n            for batch in pbar:\n                batch_start = time.time()\n                \n                for key in batch:\n                    if isinstance(batch[key], torch.Tensor):\n                        batch[key] = batch[key].to(self.device)\n                \n                modality_indicators = self._create_modality_indicators(batch)\n                \n                if self.config.mixed_precision and self.scaler:\n                    with autocast():\n                        outputs = self.model(batch)\n                        loss_dict = compute_total_loss_corrected(\n                            outputs['predictions'], batch['labels'], outputs, \n                            modality_indicators, beta=self.config.cmi_loss_weight,\n                            focal_gamma=self.config.focal_gamma\n                        )\n                else:\n                    outputs = self.model(batch)\n                    loss_dict = compute_total_loss_corrected(\n                        outputs['predictions'], batch['labels'], outputs, \n                        modality_indicators, beta=self.config.cmi_loss_weight,\n                        focal_gamma=self.config.focal_gamma\n                    )\n                \n                batch_time = time.time() - batch_start\n                \n                self.val_metrics.update(\n                    outputs['predictions'], batch['labels'],\n                    loss_dict['total_loss'], loss_dict['classification_loss'], loss_dict['cmi_loss'],\n                    batch_time\n                )\n        \n        pbar.close()\n        return self.val_metrics.compute_rsna_metrics()\n    \n    def print_results(self, epoch, train_results, val_results):\n        \"\"\"Print comprehensive results\"\"\"\n        print(f\"\\nðŸš€ EPOCH {epoch+1} RESULTS:\")\n        print(\"=\"*120)\n        \n        # Main metrics\n        print(f\"ðŸ“Š Main Metrics:\")\n        print(f\"   Train - Loss: {train_results['loss']:.4f}, AUC: {train_results['mean_auc']:.4f}\")\n        print(f\"   Val   - Loss: {val_results['loss']:.4f}, AUC: {val_results['mean_auc']:.4f}\")\n        \n        # Loss breakdown\n        print(f\"ðŸ“‰ Loss Breakdown:\")\n        print(f\"   Train - Class: {train_results['classification_loss']:.4f}, CMI: {train_results['cmi_loss']:.4f}\")\n        print(f\"   Val   - Class: {val_results['classification_loss']:.4f}, CMI: {val_results['cmi_loss']:.4f}\")\n        \n        print(\"=\"*120)\n    \n    def train(self, train_loader, val_loader):\n        \"\"\"Complete production training\"\"\"\n        print(f\"ðŸš€ STARTING PRODUCTION DVG TRAINING:\")\n        print(\"=\"*120)\n        \n        self.start_time = time.time()\n        \n        for epoch in range(self.config.num_epochs):\n            print(f\"\\nðŸ”„ EPOCH {epoch+1}/{self.config.num_epochs}\")\n            \n            # Train and validate\n            train_results = self.train_epoch(train_loader, epoch)\n            val_results = self.validate_epoch(val_loader, epoch)\n            \n            # Scheduler step\n            self.scheduler.step()\n            \n            # Print results\n            self.print_results(epoch, train_results, val_results)\n            \n            # Early stopping check\n            should_stop, stop_reason, improved = self.early_stopping.step(\n                epoch, val_results, self.model, self.optimizer\n            )\n            \n            # Save history\n            self.training_history.append({\n                'epoch': epoch,\n                'train': train_results,\n                'val': val_results,\n                'timestamp': datetime.now().isoformat()\n            })\n            \n            # Save checkpoints\n            if self.config.checkpoint_config['save_checkpoints']:\n                self.checkpoint_manager.save_latest_checkpoint(\n                    self.model, self.optimizer, self.scheduler, self.scaler,\n                    epoch, train_results, val_results, self.training_history, self.config\n                )\n                \n                if improved:\n                    self.checkpoint_manager.save_best_checkpoint(\n                        self.model, self.optimizer, self.scheduler, self.scaler,\n                        epoch, train_results, val_results, self.training_history, self.config\n                    )\n                \n                self.checkpoint_manager.save_periodic_checkpoint(\n                    self.model, self.optimizer, self.scheduler, self.scaler,\n                    epoch, train_results, val_results, self.training_history, self.config\n                )\n            \n            # Check for early stopping\n            if should_stop:\n                print(f\"\\nðŸ›‘ EARLY STOPPING TRIGGERED: {stop_reason}\")\n                break\n        \n        # Save final checkpoint\n        if self.config.checkpoint_config['save_checkpoints']:\n            self.checkpoint_manager.save_final_checkpoint(\n                self.model, self.optimizer, self.scheduler, self.scaler,\n                epoch, train_results, val_results, self.training_history, self.config, stop_reason\n            )\n        \n        total_time = time.time() - self.start_time\n        print(f\"\\nðŸŽ‰ TRAINING COMPLETED!\")\n        print(f\"   â±ï¸ Total Time: {total_time/3600:.1f} hours\")\n        print(f\"   ðŸ† Best Score: {self.early_stopping.best_primary_score:.4f}\")\n        \n        return self.training_history\n\n# ================================================================================\n# MAIN FUNCTION\n# ================================================================================\ndef train_production_dvg_corrected():\n    \"\"\"Production training with innovations applied\"\"\"\n    \n    print(\"=\"*140)\n    print(\"ðŸš€ DVG-M4oE PRODUCTION TRAINING - CORRECTED VERSION\")\n    print(\"=\"*140)\n    \n    config = ProductionConfigFixed()\n    \n    print(f\"ðŸ“¥ Creating production dataloaders...\")\n    train_loader, val_loader = get_dvg_dataloaders(\n        csv_path=config.csv_path,\n        data_root=config.data_root,\n        clean_files_path=config.clean_files_path,\n        batch_size=config.batch_size,\n        num_workers=config.num_workers,\n        target_size=(32, 358, 358),\n        verbose=True\n    )\n    \n    trainer = ProductionTrainerFixed(config)\n    history = trainer.train(train_loader, val_loader)\n    \n    return trainer, history\n\n# ================================================================================\n# EXECUTION\n# ================================================================================\nif __name__ == \"__main__\":\n    try:\n        trainer, history = train_production_dvg_corrected()\n        print(f\"\\nðŸ† TRAINING COMPLETED SUCCESSFULLY!\")\n        \n    except Exception as e:\n        print(f\"âŒ Training failed: {e}\")\n        import traceback\n        traceback.print_exc()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-13T04:43:36.342446Z","iopub.execute_input":"2025-10-13T04:43:36.343017Z","execution_failed":"2025-10-13T04:52:54.262Z"}},"outputs":[],"execution_count":null}]}